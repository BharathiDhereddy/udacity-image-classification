{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BharathiDhereddy/udacity-image-classification/blob/master/Udacity_Image_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXrmsdwUqWKe",
        "outputId": "ab4a625e-7e56-44a5-84de-40d5cdb347eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Cloning into 'udacity-image-classification'...\n",
            "remote: Enumerating objects: 8529, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 8529 (delta 0), reused 0 (delta 0), pack-reused 8526 (from 1)\u001b[K\n",
            "Receiving objects: 100% (8529/8529), 330.33 MiB | 20.93 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Updating files: 100% (8197/8197), done.\n"
          ]
        }
      ],
      "source": [
        "# Install git if it is not already installed\n",
        "!apt-get install -q git\n",
        "\n",
        "# Clone the repository created in the github account\n",
        "!git clone https://github.com/BharathiDhereddy/udacity-image-classification.git\n",
        "\n",
        "# Moving all files and folders to the /content folder\n",
        "!mv udacity-image-classification/* /content/\n",
        "\n",
        "# Optional: Removing the non-empty directory\n",
        "!rm -r udacity-image-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH2gftkhz308"
      },
      "source": [
        "# Use Google Colab\n",
        "\n",
        "Use T4 GPU\n",
        "\n",
        "For it Click on the drop-down box - connect\n",
        "then change runtime type\n",
        "select T4 GPU\n",
        "Saved**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1vZJP14qjc8",
        "outputId": "5096b5b7-ac26-4618-fd10-62cfab3b4037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Necessary Libraries are  imported successfully.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary packages for image classification\n",
        "\n",
        "import time\n",
        "from PIL import Image\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "from torchvision import datasets, models\n",
        "from torchvision import  transforms as tfs\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(\"Necessary Libraries are  imported successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiSAw3qtqrqv",
        "outputId": "8f756199-bd11-47c0-e1b2-1bfea536d21a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Defining the directories\n",
        "dataset_dir = 'flowers'\n",
        "training_dir = dataset_dir + '/train'\n",
        "validation_dir = dataset_dir + '/valid'\n",
        "testing_dir = dataset_dir + '/test'\n",
        "\n",
        "# Define transformations for the training dataset\n",
        "training_transforms = tfs.Compose([tfs.RandomRotation(30),\n",
        "                                       tfs.RandomResizedCrop(224),\n",
        "                                       tfs.RandomHorizontalFlip(),\n",
        "                                       tfs.ToTensor(),\n",
        "                                       tfs.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "# Define transformations for the validation dataset\n",
        "validation_transforms = tfs.Compose([tfs.Resize(256),\n",
        "                                       tfs.CenterCrop(224),\n",
        "                                       tfs.ToTensor(),\n",
        "                                       tfs.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Define transformations for the testing dataset\n",
        "testing_transforms = tfs.Compose([tfs.Resize(256),\n",
        "                                      tfs.CenterCrop(224),\n",
        "                                      tfs.ToTensor(),\n",
        "                                      tfs.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Loading dataset with ImageFolder\n",
        "train_data = datasets.ImageFolder(training_dir, transform=training_transforms)\n",
        "test_data = datasets.ImageFolder(testing_dir, transform=testing_transforms)\n",
        "valid_data = datasets.ImageFolder(validation_dir, transform=validation_transforms)\n",
        "\n",
        "# Defining the dataloaders for loading the dataset\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)\n",
        "validloader = torch.utils.data.DataLoader(valid_data, batch_size=32)\n",
        "\n",
        "print(\"Data has loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX_r5qZAqtEx",
        "outputId": "509f8cb0-6a94-4ec6-d5a8-184ac31bdd41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category to name mapping loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Loading and mapping from Category Label to Category Name\n",
        "with open('cat_to_name.json', 'r') as fs:\n",
        "    cat_to_name = json.load(fs)\n",
        "\n",
        "print(\"Category to name mapping loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpmMeSF9quiH",
        "outputId": "9280ce02-595f-4f5f-e3f6-638f64d192ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 104MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has been built successfully.\n"
          ]
        }
      ],
      "source": [
        "# Loading a pre-trained vgg16 network\n",
        "Model = models.vgg16_bn(pretrained=True)\n",
        "\n",
        "\n",
        "# Freezing parameters so we don't backprop through them.\n",
        "for params in Model.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "# Unfreezing the classifier parameters\n",
        "for param in Model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Defining a new and untrained feed-forward network as a classifier\n",
        "clf = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(25088, 4096)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('dropout', nn.Dropout(0.2)),\n",
        "                          ('fc2', nn.Linear(4096, 102)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "Model.classifier = clf\n",
        "\n",
        "print(\"Model has been built successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN4gwLukrZYI"
      },
      "outputs": [],
      "source": [
        "# Set the device to GPU or CPU\n",
        "devices = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "Model.to(devices)\n",
        "\n",
        "criteria = nn.NLLLoss()\n",
        "optimizers = optim.Adam(Model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "steps = 0\n",
        "print_every = len(trainloader)  # This ensures the summary is printed once per epoch\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    runningloss = 0\n",
        "    for input, label in trainloader:\n",
        "        steps += 1\n",
        "\n",
        "        input, label = input.to(devices), label.to(devices)\n",
        "\n",
        "        optimizers.zero_grad()\n",
        "\n",
        "        logps = Model.forward(input)\n",
        "        loss = criteria(logps, label)\n",
        "        loss.backward()\n",
        "        optimizers.step()\n",
        "\n",
        "        runningloss += loss.item()\n",
        "\n",
        "        if steps % print_every == 0:\n",
        "            validloss = 0\n",
        "            acc = 0\n",
        "            Model.eval()\n",
        "            with torch.no_grad():\n",
        "                for input, label in validloader:\n",
        "                    input, label = input.to(devices), label.to(devices)\n",
        "                    logps = Model.forward(input)\n",
        "                    batchloss = criteria(logps, label)\n",
        "\n",
        "                    validloss += batchloss.item()\n",
        "\n",
        "                    # Calculatiing the accuracy of the model\n",
        "                    p = torch.exp(logps)\n",
        "                    top_p, top_class = p.topk(1,dim=1)\n",
        "                    equal = top_class == label.view(*top_class.shape)\n",
        "                    acc += torch.mean(equal.type(torch.FloatTensor)).item()\n",
        "\n",
        "            print(f\"Epochs: {epoch+1}/{epochs}.. \"\n",
        "                  f\"Train Loss: {runningloss/len(trainloader):.3f}.. \"\n",
        "                  f\"Validation Loss: {validloss/len(validloader):.3f}.. \"\n",
        "                  f\"Validation Accuracy: {acc/len(validloader) * 100:.2f}%\")\n",
        "            runningloss = 0\n",
        "            Model.train()\n",
        "\n",
        "print(\"Training completed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VVFCXkpRorV6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDvEmNrgrhE6"
      },
      "outputs": [],
      "source": [
        "# Test the network\n",
        "testloss = 0\n",
        "acc = 0\n",
        "Model.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    for input, label in testloader:  # Replace 'dataloaders['test']' with 'testloader'\n",
        "        input, label = input.to('cuda'), label.to('cuda')\n",
        "        logps = Model.forward(input)\n",
        "        batchloss = criteria(logps, label)\n",
        "        testloss += batchloss.item()\n",
        "\n",
        "\n",
        "        p = torch.exp(logps)\n",
        "        top_p, top_class = p.topk(1, dim=1)\n",
        "        equal = top_class == label.view(*top_class.shape)\n",
        "        acc += torch.mean(equal.type(torch.FloatTensor)).item()\n",
        "\n",
        "print(f\"Test Loss: {testloss/len(testloader):.3f}.. \"  # Also replace here\n",
        "      f\"Test Accuracy: {acc/len(testloader):.3f}\")  # And here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59H4LcnVrxDp"
      },
      "outputs": [],
      "source": [
        "# Saving the model checkpoint\n",
        "checkpoint = {\n",
        "    'state_dict': Model.state_dict(),\n",
        "    'class_to_idx': Model.class_to_idx,\n",
        "    'classifier': clf,  # Save the classifier correctly\n",
        "    'arch': 'vgg16_bn'  # Save the architecture to match loading\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEeftVjWrzWD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_checkpoint(file_path):\n",
        "    checkpoint = torch.load(file_path)\n",
        "    Model = models.vgg16(pretrained=True)\n",
        "\n",
        "    for params in Model.parameters():\n",
        "        params.requires_grad = False\n",
        "\n",
        "    Model.clf = nn.Sequential(OrderedDict([\n",
        "        ('FC1', nn.Linear(25088, 4096)),\n",
        "        ('Relu', nn.ReLU()),\n",
        "        ('Dropout', nn.Dropout(0.5)),\n",
        "        ('FC2', nn.Linear(4096, 102)),\n",
        "        ('Output', nn.LogSoftmax(dim=1))\n",
        "    ]))\n",
        "    Model.classifier = checkpoint['classifier']  # Load the saved classifier\n",
        "    Model.load_state_dict(checkpoint['state_dict'])\n",
        "    Model.class_to_idx = checkpoint['class_to_idx']\n",
        "\n",
        "    return Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6wWULcjsGRg"
      },
      "outputs": [],
      "source": [
        "def processimage(imagepath):\n",
        "    pilImage = Image.open(imagepath)\n",
        "    pilImage = pilImage.resize((256, 256))\n",
        "    left = (pilImage.width - 224) / 2\n",
        "    top = (pilImage.height - 224) / 2\n",
        "    right = (pilImage.width + 224) / 2\n",
        "    bottom = (pilImage.height + 224) / 2\n",
        "    pilImage = pilImage.crop((left, top, right, bottom))\n",
        "    npImage = np.array(pilImage) / 255\n",
        "    mean_n = np.array([0.485, 0.456, 0.406])\n",
        "    std_n = np.array([0.229, 0.224, 0.225])\n",
        "    npImage = (npImage - mean_n) / std_n\n",
        "    npImage = npImage.transpose((2, 0, 1))\n",
        "    return torch.tensor(npImage).float()\n",
        "\n",
        "def predict(imagepath, Model, topk=5):\n",
        "    image = processimage(imagepath)\n",
        "    image = image.unsqueeze(0)\n",
        "    Model.eval()\n",
        "    # Move the image to the same device as the model\n",
        "    image = image.to(devices)  # Add this line\n",
        "    with torch.no_grad():\n",
        "        outputs = Model(image)\n",
        "        p = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        top_p, top_class = p.topk(topk, dim=1)\n",
        "        idx_to_class = {v: k for k, v in Model.class_to_idx.items()}\n",
        "        top_class = top_class.cpu().numpy()[0]\n",
        "        top_class = [idx_to_class[i] for i in top_class]\n",
        "    return top_p.cpu().numpy()[0], top_class\n",
        "\n",
        "print(\"Inference function for classification is ready.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-S7VLgdsQkz"
      },
      "outputs": [],
      "source": [
        "def imshow(image, ax=None, title=None):\n",
        "    if ax is None:\n",
        "        figure, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    mean_n = np.array([0.485, 0.456, 0.406])\n",
        "    std_n = np.array([0.229, 0.224, 0.225])\n",
        "    image = std_n * image + mean_n\n",
        "    image = np.clip(image, 0, 1)\n",
        "    ax.imshow(image)\n",
        "    return ax\n",
        "\n",
        "import seaborn as sns\n",
        "def plotsolution(imagepath, Model):\n",
        "    plt.figure(figsize=(5,9))\n",
        "    ax = plt.subplot(2,1,1)\n",
        "    img = processimage(imagepath)\n",
        "    flowerclass = imagepath.split('/')[-2]\n",
        "    title = cat_to_name.get(flowerclass, 'Unknown Flower')\n",
        "    imshow(img, ax, title=title)\n",
        "    prob, classes= predict(imagepath, Model)\n",
        "    class_names = [cat_to_name.get(item, 'Unknown Flower') for item in classes]\n",
        "    plt.subplot(2,1,2)\n",
        "    sns.barplot(x=prob, y=class_names, color=sns.color_palette()[0])\n",
        "    plt.show()\n",
        "\n",
        "print(\"Prediction display function is ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRv5XbbcvGKA"
      },
      "outputs": [],
      "source": [
        "devices = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "Model.to(devices)\n",
        "print(\"Model has loaded:\", devices)\n",
        "\n",
        "# Process and predict\n",
        "imagepath = '/content/flowers/test/1/image_06743.jpg'\n",
        "img = processimage(imagepath)\n",
        "print(\"Image processed successfully.\")\n",
        "\n",
        "prob, classes = predict(imagepath, Model)\n",
        "print(\"Prediction probabilities: \", prob)\n",
        "print(\"Prediction class: \", classes)\n",
        "\n",
        "# Display the result\n",
        "plotsolution(imagepath, Model)\n",
        "print(\"Prediction completed successfully.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}